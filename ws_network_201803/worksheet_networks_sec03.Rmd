---
title: "Dublin Data Science Workshop on the Statistical Analysis of Networks"
subtitle: "Section 3"
author: "Mick Cooney <mickcooney@gmail.com>"
date: "Monday, April 30 2018"
output:
  html_document:
    fig_caption: yes
    number_sections: yes
    theme: cerulean
    toc: yes
  word_document:
    toc: yes
  pdf_document: default
---

```{r knit_opts, include = FALSE}
knitr::opts_chunk$set(tidy  = FALSE
                     ,cache = FALSE
                     ,message = FALSE
                     ,warning = FALSE
                     ,fig.height =  8
                     ,fig.width  = 11)

library(tidyverse)
library(scales)
library(cowplot)

library(ggnetwork)
library(igraph)
library(igraphdata)
library(sand)


options(width = 80L
       ,warn  = 1
        )

set.seed(42)


source('data_setup.R')

source('custom_functions.R')
```





# Random Graph Models

We now move on to modelling graph data using statistical methods.

To begin, we start with very simple generative processes for graphs,
investigating how we can use these methods to approximate data we have.

## Traditional Models

We start with basic statistical models where models are produced purely at
random to match basic measures of graphs such as node and edge count, degree
distributions and so on.

The building block for these are *Erdos-Renyi* models, probably the simplest
models we can produce.


### Erdos-Renyi Graph Models

The simplest random graph model is one where we have a fixed number of nodes
and have either a fixed count of edges with equally likely probability - the 
$G(n,m)$ model, or we assign each edge a fixed probability of occurring - the
$G(n,p)$ model.

We start with the $G(n,m)$ model on a network with 50 nodes so that processing
and visualisation is fast.

```{r show_gnm_models, echo=TRUE}
gnmsample_igraph <- sample_gnm(50, 75)

ggplot(ggnetwork(gnmsample_igraph, layout = 'fruchtermanreingold')
      ,aes(x = x, y = y, xend = xend, yend = yend)) +
    geom_edges() +
    geom_label(aes(label = vertex.names)) +
    ggtitle('Sample G(n,m) Graph') +
    theme_blank()
    
ggplot(ggnetwork(gnmsample_igraph, layout = 'circle')
      ,aes(x = x, y = y, xend = xend, yend = yend)) +
    geom_edges() +
    geom_label(aes(label = vertex.names)) +
    ggtitle('Sample G(n,m) Graph with Circular Layout') +
    theme_blank()

```

Similarly, we generate a $G(n, p)$ graph.

```{r show_gnp_models, echo=TRUE}
gnpsample_igraph <- sample_gnp(50, 0.05)

ggplot(ggnetwork(gnpsample_igraph, layout = 'fruchtermanreingold')
      ,aes(x = x, y = y, xend = xend, yend = yend)) +
    geom_edges() +
    geom_label(aes(label = vertex.names)) +
    ggtitle('Sample G(n,p) Graph') +
    theme_blank()
    
ggplot(ggnetwork(gnpsample_igraph, layout = 'circle')
      ,aes(x = x, y = y, xend = xend, yend = yend)) +
    geom_edges() +
    geom_label(aes(label = vertex.names)) +
    ggtitle('Sample G(n,p) Graph with Circular Layout') +
    theme_blank()
```


### Generalised Random Graph Models

Expanding this concept, we can generate graphs based on more advanced measures
of the graph, such as the degree distribution.

To show how this works, we create a 50-node graph where each node has a degree between
1 and 4.

```{r sample_degree_dist_graph, echo=TRUE}
sample_degreedist <- sample(1:4, 50, replace = TRUE)

degdistsample_igraph <- sample_degseq(sample_degreedist, method = 'simple.no.multiple')

ggplot(ggnetwork(degdistsample_igraph)
      ,aes(x = x, y = y, xend = xend, yend = yend)) +
    geom_edges() +
    geom_label(aes(label = vertex.names)) +
    ggtitle('Sample Degree Distribution Graph') +
    theme_blank()
```

More advanced algorithms exist to construct random graphs on other
characteristics, but most of those rely on Markov Chain Monte Carlo methods
and are beyond the scope of this workshop.

### Assessing Random Graph Models

Now that we have a few methods for producing these random graphs, the next
logical issue is assessing how well these models capture aspects of our data.

#### Florentine Marriage Network

As an example, we use the Florentine dataset, and produce some random graphs
that match our data and compare the other measures such as clustering, diameter
and average path length to what our models produce.

*NOTE:* This code may look a little cryptic and overly-concise at first, as I use
functional methods to produce the simulations. There is nothing fancy
happening here, so look up the functions in `purrr` if you get confused.

```{r model_florentine_data_gnm, echo=TRUE}
n_iter <- 1000

flor_count_node <- gorder(florence_igraph)
flor_count_edge <- gsize (florence_igraph)

sim_data_tbl <- data_frame(sim_id = 1:n_iter) %>%
    mutate(graph      = rerun(n_iter, sample_gnm(n = flor_count_node, flor_count_edge))
          ,trans      = map_dbl(graph, transitivity)
          ,diam       = map_dbl(graph, diameter)
          ,meandist   = map_dbl(graph, mean_distance)
          ,max_degree = map_dbl(graph, function(x) x %>% igraph::degree() %>% max)
          ,n_comp     = map_dbl(graph, function(x) x %>% count_components)
          ,n_clust    = map_dbl(graph, function(x) x %>% cluster_fast_greedy() %>% length)
           )

graph_vals_tbl <- data_frame(
    parameter = c('trans','diam','meandist', 'max_degree', 'n_comp', 'n_clust')
   ,graph_val = c(florence_igraph %>% transitivity
                 ,florence_igraph %>% diameter
                 ,florence_igraph %>% mean_distance
                 ,florence_igraph %>% igraph::degree() %>% max
                 ,florence_igraph %>% count_components()
                 ,florence_igraph %>% cluster_fast_greedy() %>% length()
                 )
    )

plot_data_tbl <- sim_data_tbl %>%
    dplyr::select(-graph) %>%
    gather('parameter','value', -sim_id)


ggplot(plot_data_tbl) +
    geom_histogram(aes(x = value), bins = 50) +
    geom_vline(aes(xintercept = graph_val), colour = 'red', data = graph_vals_tbl) +
    facet_wrap(~parameter, scales = 'free') +
    scale_y_continuous(label = comma) +
    xlab('Value') +
    ylab('Count')
```

We do something similar for the G(n,p) model

```{r model_florentine_data_gnp, echo=TRUE}
n_iter <- 1000

flor_count_node <- gorder(florence_igraph)
flor_count_edge <- gsize (florence_igraph)

edge_prop <- flor_count_edge / (0.5 * flor_count_node * (flor_count_node-1))


sim_data_tbl <- data_frame(sim_id = 1:n_iter) %>%
    mutate(graph      = rerun(n_iter, sample_gnp(n = flor_count_node, p = edge_prop))
          ,trans      = map_dbl(graph, transitivity)
          ,diam       = map_dbl(graph, diameter)
          ,meandist   = map_dbl(graph, mean_distance)
          ,max_degree = map_dbl(graph, function(x) x %>% igraph::degree() %>% max)
          ,n_comp     = map_dbl(graph, function(x) x %>% count_components)
          ,n_clust    = map_dbl(graph, function(x) x %>% cluster_fast_greedy() %>% length)
           )

graph_vals_tbl <- data_frame(
    parameter = c('trans','diam','meandist', 'max_degree', 'n_comp', 'n_clust')
   ,graph_val = c(florence_igraph %>% transitivity
                 ,florence_igraph %>% diameter
                 ,florence_igraph %>% mean_distance
                 ,florence_igraph %>% igraph::degree() %>% max
                 ,florence_igraph %>% count_components()
                 ,florence_igraph %>% cluster_fast_greedy() %>% length()
                 )
    )

plot_data_tbl <- sim_data_tbl %>%
    dplyr::select(-graph) %>%
    gather('parameter','value', -sim_id)


ggplot(plot_data_tbl) +
    geom_histogram(aes(x = value), bins = 50) +
    geom_vline(aes(xintercept = graph_val), colour = 'red', data = graph_vals_tbl) +
    facet_wrap(~parameter, scales = 'free') +
    scale_y_continuous(label = comma) +
    xlab('Value') +
    ylab('Count')
```

The $G(n,p)$ model looks very similar, as expected.

Finally, We also try the degree distribution sample


```{r model_florentine_data_degreedist, echo=TRUE}
flor_degdist <- igraph::degree(florence_igraph)


sim_data_tbl <- data_frame(sim_id = 1:n_iter) %>%
    mutate(graph      = rerun(n_iter, sample_degseq(flor_degdist) %>% simplify())
          ,trans      = map_dbl(graph, transitivity)
          ,diam       = map_dbl(graph, diameter)
          ,meandist   = map_dbl(graph, mean_distance)
          ,max_degree = map_dbl(graph, function(x) x %>% igraph::degree() %>% max)
          ,n_comp     = map_dbl(graph, function(x) x %>% count_components)
          ,n_clust    = map_dbl(graph, function(x) x %>% cluster_fast_greedy() %>% length)
           )

graph_vals_tbl <- data_frame(
    parameter = c('trans','diam','meandist', 'max_degree', 'n_comp','n_clust')
   ,graph_val = c(florence_igraph %>% transitivity
                 ,florence_igraph %>% diameter
                 ,florence_igraph %>% mean_distance
                 ,florence_igraph %>% igraph::degree() %>% max
                 ,florence_igraph %>% count_components()
                 ,florence_igraph %>% cluster_fast_greedy() %>% length()
                 )
    )

plot_data_tbl <- sim_data_tbl %>%
    dplyr::select(-graph) %>%
    gather('parameter','value', -sim_id)


ggplot(plot_data_tbl) +
    geom_histogram(aes(x = value), bins = 50) +
    geom_vline(aes(xintercept = graph_val), colour = 'red', data = graph_vals_tbl) +
    facet_wrap(~parameter, scales = 'free') +
    scale_y_continuous(label = comma) +
    xlab('Value') +
    ylab('Count')
```

While small and useful to illustrate the basics, the Florentine marriage network
may not be a sound example for the purposes of illustrating the quality of these
statistical models.

Due to its small size, the number of possible networks with these node and edge
counts is low, so it is likely that any random graph will agree with it because
of this.

It is more instructive to try larger networks, and see how effective
these simple models are at reconstructing them.

*SPOILER ALERT*: They kinda suck at it


#### Lazega Network

We now try the above models on the Lazega data

```{r model_lazega_data_gnm, echo=TRUE}
lazega_count_node <- gorder(lazega_igraph)
lazega_count_edge <- gsize (lazega_igraph)

run_gnm <- function() sample_gnm(n = lazega_count_node, lazega_count_edge)

lazega_gnm_lst <- run_network_model_assessment(lazega_igraph, run_gnm, n_iter = 1000)

plot(lazega_gnm_lst$assess_plot)
```

As you can see, the Lazega network is larger than the Florentine network
(though still small in absolute terms) and we already see that the observed
values of the network differ from our simulations.

The clustering coefficient in the Lazega network in particular is not well
captured by the model.

We try the degree distribution model too, and see if that does a better job.

```{r model_lazega_data_degdist, echo=TRUE}
lazega_degdist <- lazega_igraph %>% igraph::degree()

run_degdist <- function() sample_degseq(lazega_degdist) %>% simplify()

lazega_degdist_lst <- run_network_model_assessment(lazega_igraph, run_degdist, n_iter = 1000)

plot(lazega_degdist_lst$assess_plot)
```

We see similar results to before, but once again the clustering is not well
captured.


## Mechanistic Random Graph Models

Our basic random graph models do not capture the higher levels of clustering
observed in real-world networks.


### Small World Models

The basic small world model is the Watts-Strogatz model. This creates a lattice
network of size $N$, connecting all neighbours within a particular path length
$k$, giving us a total edge count of $Nk$. We then randomly move the edges to
other nodes with probabiity $p$.

For $p=0$, we have a transitivity value $C(p)$ of

$$
C(p) = \frac{3(k-2)}{4(k-1)} . (1 - p)^3
$$

To fit this model to real data, we set $k$ from the edge count, and then fit
the appropriate $p$ to match our observed transitivity.


```{r fit_lazega_watts_strogatz, echo=TRUE}
lazega_node_count <- lazega_igraph %>% vcount()
lazega_edge_count <- lazega_igraph %>% ecount()
lazega_cluster    <- lazega_igraph %>% transitivity()

lazega_k <- (lazega_edge_count / lazega_node_count) %>% ceiling()


calc_trans <- function(p_iter) {
    trans <- rerun(10, sample_smallworld(1, lazega_node_count, lazega_k, p_iter) %>% transitivity) %>%
        unlist() %>%
        mean()
    
    return(trans)
}


lazega_p <- optimize(function(x) abs(calc_trans(x) - lazega_cluster), c(0.01, 0.2))$minimum

run_ws <- function() sample_smallworld(1, size = lazega_node_count, nei = lazega_k, p = lazega_p) %>%
                        simplify()

lazega_ws_lst <- run_network_model_assessment(lazega_igraph, run_ws, n_iter = 1000)

plot(lazega_ws_lst$assess_plot)
```



### Preferential Attachment Models

With the preferential attachment model, we add new nodes and weight the
probability of attachment to existing nodes by the degree of each node.

In the simple model, we use a probability weight as

$$
P(v_i) = \frac{d_{v_i}}{\sum_{v_j \in V} d_{v_j}}
$$

As the network grows, we have a 'rich get richer' effect as nodes
on the network tend to get more and more nodes attached to them.

```{r show_preferential_attachment_graph, echo=TRUE}
samplepa_igraph <- sample_pa(50, power = 1, m = 1, directed = FALSE)

samplepa_plot <- ggplot(samplepa_igraph
                       ,aes(x = x, y = y, xend = xend, yend = yend)) +
    geom_edges() +
    geom_label(aes(label = vertex.names)) +
    theme_blank()

samplepa_plot %>% plot()
```

For the degree distribution, we expect a small number of high degree nodes
and the rest being low counts.

```{r prefattach_degree_dist, echo=TRUE}
samplepa_degdist <- igraph::degree(samplepa_igraph)

summary(samplepa_degdist)

ggplot() +
    geom_histogram(aes(x = samplepa_degdist), bins = 20) +
    xlab("Degree") +
    ylab("Node Count")
```

Asymptotically, the degree distribution tends towards a power law of the form

$$
P(d) \sim d^{-3}
$$

Because of this tail effect, we will generate a bigger network and look at the
degree distribution.

```{r generate_larger_pa_graph, echo=TRUE}
largepa_degreedist <- sample_pa(1000, power = 1, m = 1, directed = FALSE) %>%
    igraph::degree()

summary(largepa_degreedist)

ggplot() +
    geom_histogram(aes(x = largepa_degreedist), bins = 50) +
    xlab("Degree") +
    ylab("Node Count")
```


We now look at some basic comparisons of the Preferential Attachment model to
the Lazega network

```{r fit_lazega_pref_attach, echo=TRUE}
lazega_node_count <- lazega_igraph %>% vcount()

run_pa <- function() sample_pa(lazega_node_count, power = 1, m = 1, directed = FALSE) %>%
                        simplify()

lazega_pa_lst <- run_network_model_assessment(lazega_igraph, run_pa, n_iter = 1000)

plot(lazega_pa_lst$assess_plot)
```

As we see, the transitivity for the Preferential Attachment models tend to be
very low.


# R Environment

```{r show_session_info, echo=TRUE, message=TRUE}
devtools::session_info()
```

