---
title: "An Introduction to Insurance Pricing, GLMs and Model Validation"
subtitle: "Dublin Data Science"
author: "Mick Cooney"
date: "2017-08-24"
output:
  revealjs::revealjs_presentation:
    css: custom.css
    theme: night
    highlight: pygments
    center: true
    reveal_options:
      slideNumber: true
---

```{r knit_opts, include = FALSE}
knitr::opts_chunk$set(tidy  = FALSE
                     ,cache = FALSE
                     ,fig.height =  8
                     ,fig.width  = 11)

library(tidyverse)
library(forcats)
library(scales)
library(purrr)
library(broom)
library(poweRlaw)
library(cowplot)


options(width = 80L)


clean_names <- function(colnames) {
    colnames <- gsub(" ",        "_", colnames)
    colnames <- gsub("/",        "_", colnames)
    colnames <- gsub("\\.",      "_", colnames)
    colnames <- gsub("\\-",      "_", colnames)
    colnames <- gsub("'",         "", colnames)
    colnames <- gsub("`",         "", colnames)
    colnames <- gsub("\\(",       "", colnames)
    colnames <- gsub("\\)",       "", colnames)
    colnames <- gsub("\\?",       "", colnames)
    colnames <- gsub("\\%",       "", colnames)
    colnames <- gsub("\u2019",    "", colnames)
    colnames <- gsub("\u20AC", "EUR", colnames)

    colnames <- colnames %>%
        gsub('(.)([A-Z][a-z]+)',  '\\1_\\2', .) %>%
        gsub('([a-z0-9])([A-Z])', '\\1_\\2', .) %>%
        tolower

    colnames <- gsub("__+", "_", colnames)

    return(colnames)
}
```

# Background

## Computational Actuarial Science

![](img/computational_actuarial_science_cover.jpg)


## Insurance Business

\

Life Insurance

\

General Insurance

\

(Health Insurance)

---

Pay premia

\

If event occurs, receive payout


---

How do we calculate premia?

---

How *SHOULD* we calculate premia?

---

$$
\text{Price} = E(\text{Loss}) + \text{Expenses} + \text{Profit}
$$

---

Focus on calculation of "Loss Cost"


## Life Insurance

\

Monthly or annual premia

\

Contingent annuity

\

Life Tables



## Pricing General Insurance

\

Typically 1-year policies

\

(but not always)


---

Estimate Loss Cost of a Policy

---

Frequency / Severity Model

\

Exposure vs Claims

\

Heavy use of GLMs


---

$$
\text{Price} = E[\text{Claim Rate}] \times E[\text{Claim Size}]
$$

---

Claim Rate $\longrightarrow$ Poisson

\

Claim Amount $\longrightarrow$ Gamma

---

Need policy and claim data

---

Package `CASDatasets`

\

`freMPTLfreq` and `freMPTLsev`

\

More datasets in book


# Data Loading and Exploration

```{r load_data, echo=TRUE}
library(CASdatasets)

data(freMTPLfreq)
data(freMTPLsev)
```

---

```{r show_frequency_data_head, echo=FALSE}
freMTPLfreq %>% head %>% (knitr::kable)(digits = 2)
```

---

```{r show_frequency_data_glimpse, echo=FALSE}
freMTPLfreq %>% glimpse
```

---

```{r show_severity_data_head, echo=FALSE}
freMTPLsev %>% head(n = 15) %>% (knitr::kable)(digits = 2)
```


## Combine Tables


```{r basic_data_transforms, echo=FALSE}
policy_tbl <- freMTPLfreq %>% as_data_frame
claim_tbl  <- freMTPLsev  %>% as_data_frame

names(policy_tbl) <- policy_tbl %>% names %>% clean_names
names(claim_tbl)  <- claim_tbl  %>% names %>% clean_names
```

```{r combine_policies_claims, echo=TRUE}
policy_claims_tbl <- claim_tbl %>%
    group_by(policy_id) %>%
    summarise(claim_count = n()
             ,claim_total = sum(claim_amount))

combined_tbl <- policy_tbl %>%
    left_join(policy_claims_tbl, by = 'policy_id') %>%
    mutate(claim_count = ifelse(is.na(claim_count), 0, claim_count)
          ,claim_total = ifelse(is.na(claim_total), 0, claim_total)
           )
```

---

```{r combined_table, echo=FALSE}
combined_tbl %>% head %>% (knitr::kable)(digits = 2)
```

---

```{r combined_table_dataclean, echo=TRUE}
combined_tbl %>% filter(claim_nb != claim_count)
```


## Univariate Data Exploration

\

Look at each variable

\

Create histograms, bar charts etc

\

`dataexpks` - data exploration template

---

### claim_count

```{r explore_claim_count, echo=FALSE, fig.height=7.5, fig.width=11}
ggplot(combined_tbl) +
    geom_bar(aes(x = claim_count)) +
    scale_y_continuous(labels = comma) +
    xlab("Claim Count") +
    ylab("Policy Count") +
    ggtitle("Histogram of Claim Counts per Policy")
```

---

```{r explore_claim_count_nonzero, echo=FALSE, fig.height=8, fig.width=11}
ggplot(combined_tbl %>% filter(claim_count > 0)) +
    geom_bar(aes(x = claim_count)) +
    scale_y_continuous(labels = comma) +
    xlab("Claim Count") +
    ylab("Policy Count") +
    ggtitle("Histogram of Claim Counts per Policy with Claims")
```

---

### claim_amount

```{r explore_claim_amount, echo=FALSE, fig.height=7.5, fig.width=11}
ggplot(claim_tbl) +
    geom_histogram(aes(x = claim_amount), bins = 50) +
    scale_x_continuous(labels = comma) +
    scale_y_continuous(labels = comma) +
    xlab("Claim Amount") +
    ylab("Policy Count") +
    ggtitle("Histogram of Claim Amounts")
```

---

```{r explore_claim_amount_operational, echo=FALSE, fig.height=8, fig.width=11}
ggplot(claim_tbl %>% filter(claim_amount <= 25000)) +
    geom_histogram(aes(x = claim_amount), bins = 50) +
    scale_x_continuous(labels = comma) +
    scale_y_continuous(labels = comma) +
    xlab("Claim Amount") +
    ylab("Policy Count") +
    ggtitle("Histogram of Non-Large Claim Amounts")
```

---


### exposure

```{r explore_exposure, echo=FALSE, fig.height=7.5, fig.width=11}
ggplot(combined_tbl) +
    geom_histogram(aes(x = exposure), bins = 50) +
    scale_y_continuous(labels = comma) +
    xlab("Policy Exposure") +
    ylab("Policy Count") +
    ggtitle("Histogram of Exposures in Policies")
```

---

### driver_age

```{r explore_driver_age, echo=FALSE, fig.height=7.5, fig.width=11}
ggplot(combined_tbl) +
    geom_histogram(aes(x = driver_age), bins = 30) +
    scale_y_continuous(labels = comma) +
    xlab("Driver Age") +
    ylab("Policy Count") +
    ggtitle("Histogram of Driver Ages")
```

---

### car_age

```{r explore_car_age, echo=FALSE, fig.height=7.5, fig.width=11}
ggplot(combined_tbl) +
    geom_histogram(aes(x = car_age), bins = 50) +
    scale_y_continuous(labels = comma) +
    xlab("Car Age") +
    ylab("Policy Count") +
    ggtitle("Histogram of Car Age")
```





## Bivariate Data Exploration

\

Look at two variables at once

\

Boxplots, Scatterplots, Heatmaps, etc


---

### claim_count vs driver_age

```{r boxplot_driver_age_claim_count, echo=FALSE, fig.height=7.5, fig.width = 11}
ggplot(combined_tbl) +
    geom_boxplot(aes(x = claim_count %>% as.character, y = driver_age)) +
    xlab("Claim Count") +
    ylab("Driver Age") +
    ggtitle("Boxplot of Driver Ages by Claim Count")
```

---

### claim_count vs region

```{r faceted_plot_claim_count_region, echo=FALSE, fig.height=7.5, fig.width=11}
ggplot(combined_tbl) +
    geom_bar(aes(x = claim_count)) +
    scale_y_continuous(labels = comma) +
    facet_wrap(~region, scales = 'free_y') +
    xlab("Claim Count") +
    ylab("Policy Count") +
    ggtitle("Claim Counts by Policy Facetted by Region")
```


## Estimating Large Losses

\

Large losses very random

\

Treat like natural disasters

\

Power-law scaling

---

```{r fit_power_law, echo=FALSE}
logsize <- seq(0, 7, by = 0.1)

claimsize_count <- function(claimsize, claimdata_tbl) {
    claimdata_tbl %>%
        filter(claim_amount >= 10^claimsize) %>%
        nrow
}

powerlaw_tbl <- data_frame(
    logsize = logsize
   ,count   = map_int(logsize, claimsize_count, claimdata_tbl = claim_tbl)
)

ggplot(powerlaw_tbl) +
    geom_line(aes(x = logsize, y = log(count))) +
    xlab('Log of Claim Size') +
    ylab('Log of Claim Count') +
    ggtitle("Power-law Scaling of Claim Sizes")
```

---

```{r plot_power_law_scaling_linefit, echo=FALSE, warning=FALSE}
ggplot(powerlaw_tbl %>% filter(logsize >= 3)) +
    geom_line(aes(x = logsize, y = log(count))) +
    geom_smooth(aes(x = logsize, y = log(count)), method = 'lm', se = TRUE) +
    xlab('Log of Claim Size') +
    ylab('Log of Claim Count') +
    ggtitle("Fitted Scaling for Large Claim Sizes")
```

---

Looks reasonable

---

Slope is scaling factor, $\alpha$

\

$\alpha > 2 \; \implies \mu$ finite

\

$\alpha > 3 \; \implies $ variance finite

---

Definitely want finite $\mu$...

---


```{r plot_power_law_scaling, echo=FALSE, fig.height=7, fig.width=11}
pl_tbl <- powerlaw_tbl %>%
    filter(logsize >= 3, count > 0) %>%
    mutate(logcount  = log(count))

pl_lm <- lm(logcount ~ logsize, data = pl_tbl)

pl_lm %>% tidy %>% (knitr::kable)

pl_scaling <- pl_lm %>% tidy %>% filter(term == 'logsize') %>% pull(estimate)
```

\

Finite $\mu$, non-finite $\text{Var}(x)$


# Proposed Approach

\

$$
\text{Premium} = \text{Claim Rate} \times \text{Claim Size} + \text{Large Claim Charge}
$$
\

Claim rate more predictive power


## Model Attritional Losses

\

Use Poisson / Gamma models for rate / size

\

Estimate of attritional loss cost

\

Each policy has 'fitted' estimate


## Model Catastrophic Losses

\

Use power-law distribution

\

Estimate rate of large losses

\

Use mean loss to calculate flat charge


# Generalized Linear Models

## Basic Concept

\

\begin{eqnarray*}
E(\mathbf{Y})          &=& \mu = g^{-1}(\text{X} \beta) \\
\text{Var}(\mathbf{Y}) &=& V(\mu)
\end{eqnarray*}

\

where

\

\begin{align*}
\mathbf{Y} &= \text{response variable}      \\
\mathbf{X} &= \text{predictor variables}    \\
\beta      &= \text{model coefficients}     \\
g(x)       &= \text{link function}          \\
V(x)       &= \text{variance function}      \\
\end{align*}


---

Combines multiple forms of regression

\

\begin{eqnarray*}
\text{Linear regression}  &\longrightarrow & g(x) = x \\
\\
\text{Poisson regression} &\longrightarrow & g(x) = \log(x) \\
\\
\text{Gamma regression}   &\longrightarrow & g(x) = \frac{1}{x}
\end{eqnarray*}



## Modelling Claim Rate

\

Assuming claims occur as Poisson process

\

Regression predicts poisson rate for policy

\

Need to investigate variables

---


### Overall Claim Rate

```{r calculate_overall_claim_rate, echo=TRUE}
combined_tbl %>%
    summarise(claim_rate = sum(claim_count) / sum(exposure)) %>%
    pull(claim_rate)
```

---

### Claim Rate by Region

```{r plot_region_claim_rate, echo=FALSE, fig.height=7.5, fig.width=11}
claimrate_region_tbl <- combined_tbl %>%
    group_by(region) %>%
    summarise(claim_rate = sum(claim_count) / sum(exposure))

ggplot(claimrate_region_tbl) +
    geom_point(aes(x = region, y = claim_rate)) +
    expand_limits(y = 0) +
    xlab('Region') +
    ylab('Claim Rate') +
    ggtitle("Plot of Claim Rate by Region")
```

---

### Claim Rate by Driver Age

```{r plot_driver_age_claim_rate, echo=FALSE, fig.height=7.5, fig.width=11}
claimrate_driverage_tbl <- combined_tbl %>%
    group_by(driver_age) %>%
    summarise(claim_rate = sum(claim_count) / sum(exposure))

ggplot(claimrate_driverage_tbl) +
    geom_point(aes(x = driver_age, y = claim_rate)) +
    expand_limits(y = 0) +
    xlab('Region') +
    ylab('Driver Age') +
    ggtitle("Claim Rate by Driver Age")
```

---

### Binning driver_age

\

```{r binning_driver_age, echo=FALSE}
combined_tbl <- combined_tbl %>%
    mutate(cat_driver_age = cut(driver_age, c(17, 22, 26, 42, 74, Inf)))

combined_tbl %>%
    count(cat_driver_age) %>%
    (knitr::kable)
```


---

### First Poisson Model

```{r model_gas, echo=TRUE}
gas_glm <- glm(claim_count ~ 0 + gas
              ,offset = log(exposure)
              ,data   = combined_tbl
              ,family = poisson)

gas_glm %>% glance %>% (knitr::kable)(digits = 2)

gas_glm %>% tidy %>% (knitr::kable)(digits = 2)
```

---

### Adding Driver Age

```{r model_gas_driverage, echo=TRUE}
expmodel2_glm <- glm(claim_count ~ gas + cat_driver_age
                    ,offset = log(exposure)
                    ,data   = combined_tbl
                    ,family = poisson
)

expmodel2_glm %>% glance %>% (knitr::kable)(digits = 2)

expmodel2_glm %>% tidy %>% (knitr::kable)(digits = 2)
```

---

Reset driver age reference to `(26,42]`

```{r model_gas_driverage_redux, echo=FALSE}
combined_tbl <- combined_tbl %>%
    mutate(cat_driver_age = fct_relevel(cat_driver_age, '(26,42]'))

expmodel2_glm <- glm(claim_count ~ gas + cat_driver_age
                    ,offset = log(exposure)
                    ,data   = combined_tbl
                    ,family = poisson
)
```


```{r model_gas_driverage_redux_output, echo=TRUE}
expmodel2_glm %>% glance %>% (knitr::kable)(digits = 2)

expmodel2_glm %>% tidy %>% (knitr::kable)(digits = 2)
```


## Modelling Claim Size

\

Claim size always positive

\

Look at distribution of log of claims

---

```{r distribution_log_claim_amount, echo=FALSE}
ggplot(claim_tbl) +
    geom_histogram(aes(x = log(claim_amount)), bins = 50) +
    xlab('Log(Claim Size)') +
    ylab("Probability Density")
```

---

```{r construct_claim_reg, echo=FALSE}
claimreg_tbl <- policy_tbl %>%
    inner_join(claim_tbl, by = 'policy_id')
```


```{r model_log_claims, echo=TRUE}
expclaim_lm <- lm(log(claim_amount) ~ gas + power + car_age
                 ,data = claimreg_tbl)
```


```{r model_log_claims_output, echo=FALSE}
expclaim_lm %>% glance %>% (knitr::kable)(digits = 2)

expclaim_lm %>% tidy %>% (knitr::kable)(digits = 2)
```

---

Multiple-$R^2$ of 0.0017???

---

What does that even look like?

---

```{r visualise_claim_amount_model, echo=FALSE}
plot_tbl <- claimreg_tbl %>%
    mutate(predict_claim = expclaim_lm %>% predict(type = 'response') %>% exp)

ggplot(plot_tbl) +
    geom_point(aes(x = claim_amount, y = predict_claim), alpha = 0.1) +
    expand_limits(y = 0) +
    scale_x_continuous(labels = comma) +
    scale_y_continuous(labels = comma) +
    xlab("Actual Claim Amount") +
    ylab("Predicted Amount") +
    ggtitle("Plot of Predicted vs Actual Claim Amount")
```

---

```{r filter_smaller_claims, echo=FALSE}
claimreg_tbl <- policy_tbl %>%
    inner_join(claim_tbl, by = 'policy_id') %>%
    filter(claim_amount <= 25000)
```

```{r model_log_claims_filtered, echo=TRUE}
expclaim2_lm <- lm(log(claim_amount) ~ gas + power + car_age
                  ,data = claimreg_tbl)

expclaim2_lm %>% glance %>% (knitr::kable)(digits = 2)
```

---

```{r model_log_claims_filtered_tidy, echo=TRUE}
expclaim2_lm %>% tidy %>% (knitr::kable)(digits = 2)
```

---

```{r visualise_claim_amount_model_filtered, echo=FALSE}
plot_tbl <- claimreg_tbl %>%
    mutate(predict_claim = expclaim2_lm %>% predict(type = 'response') %>% exp)

ggplot(plot_tbl) +
    geom_point(aes(x = claim_amount, y = predict_claim), alpha = 0.1) +
    expand_limits(y = 0) +
    scale_x_continuous(labels = comma) +
    scale_y_continuous(labels = comma) +
    xlab("Actual Claim Amount") +
    ylab("Predicted Amount") +
    ggtitle("Plot of Predicted vs Actual Claim Amount for Non-Large Losses")
```

---

Pretty poor

---

Fit a Gamma?

---

```{r fit_claims_gamma, echo=TRUE}
claimgamma_glm <- glm(claim_amount ~ gas + power + car_age
                     ,family = Gamma(link = 'log')
                     ,data   = claimreg_tbl)

claimgamma_glm %>% glance %>% (knitr::kable)(digits = 2)

claimgamma_glm %>% tidy %>% (knitr::kable)(digits = 2)
```

---

```{r visualise_claims_gamma_model, echo=FALSE}
plot_tbl <- claimreg_tbl %>%
    mutate(predict_claim = claimgamma_glm %>% predict(type = 'response'))

ggplot(plot_tbl) +
    geom_point(aes(x = claim_amount, y = predict_claim), alpha = 0.1) +
    expand_limits(y = 0) +
    scale_x_continuous(labels = comma) +
    scale_y_continuous(labels = comma) +
    xlab("Actual Claim Amount") +
    ylab("Predicted Amount")
```

---

Best to have low expectations


```{r delete_files, echo=FALSE}
rm(expclaim_lm, expclaim2_lm, expmodel2_glm, gas_glm)
```



# Building a Premium Quoter

## Data Preparation

\

Remove rows:

* Drivers older than 75 years
* Cars older than 20 years

---

```{r filter_data, echo=FALSE}
modeldata_tbl <- policy_tbl %>%
    filter(driver_age <= 75
          ,car_age    <= 20) %>%
    mutate(cat_driver_age = cut(driver_age, c(17, 22, 26, 42, 74, Inf)) %>%
                                fct_relevel('(26,42]'))

modeldata_tbl %>% head %>% (knitr::kable)(digits = 2)
```

---

### Split Data

\

Standard Train/Validate/Test split

\

Take 100,000 policies for test

\

```{r split_data, echo=FALSE}
ordclaim_tbl <- modeldata_tbl %>%
    left_join(claim_tbl, by = 'policy_id') %>%
    mutate(claim_amount = ifelse(is.na(claim_amount), 0, claim_amount)) %>%
    filter(claim_amount <= 25000) %>%
    select(-claim_amount) %>%
    distinct() %>%
    arrange(policy_id)

testpolicies_tbl  <- ordclaim_tbl %>%
    sample_n(100000, replace = FALSE) %>%
    arrange(policy_id)

trainpolicies_tbl <- ordclaim_tbl %>%
    anti_join(testpolicies_tbl, by = 'policy_id') %>%
    arrange(policy_id)

valid_tbl <- trainpolicies_tbl %>%
    sample_n(50000, replace = FALSE) %>%
    arrange(policy_id)

train_tbl <- trainpolicies_tbl %>%
    anti_join(valid_tbl, by = 'policy_id') %>%
    arrange(policy_id)
```

---

```{r show_split_sizes, echo=TRUE}
train_tbl %>% nrow

valid_tbl %>% nrow

testpolicies_tbl  %>% nrow
```

---

### Model Claim Rate

```{r model_claimrate_driverage, echo=FALSE}
model_01_glm <- glm(claim_nb ~ cat_driver_age
                   ,offset = log(exposure)
                   ,family = poisson
                   ,data   = train_tbl)

model_01_glm %>% glance %>% (knitr::kable)(digits = 2)

model_01_glm %>% tidy %>% (knitr::kable)(digits = 2)
```

---

```{r model_claimrate_02, echo=FALSE}
model_02_glm <- glm(claim_nb ~ gas + cat_driver_age + car_age + density + cat_driver_age:gas
                   ,offset = log(exposure)
                   ,family = poisson
                   ,data   = train_tbl)

model_02_glm %>% glance %>% (knitr::kable)(digits = 2)

model_02_glm %>% tidy %>% (knitr::kable)(digits = 2)
```

---

### Assess Claim Rate Model

\

Predict claim frequency in train set

\

MonteCarlo simulation of claim incidence

\

Compare distribution against observed

---

```{r assess_claimfrequency_model, echo=FALSE}
n_iter <- 1000

claim_rates <- predict(model_02_glm, type = 'response')

claimrate_sim <- rpois(n_iter, sum(claim_rates))

ggplot() +
    geom_line(aes(x = claimrate_sim), stat = 'density') +
    geom_vline(aes(xintercept = train_tbl$claim_nb %>% sum), colour = 'red') +
    xlab("Claim Count")
```

---

What about the validation set?

---

```{r assess_claimfrequency_validation, echo=FALSE}
claim_rates <- predict(model_02_glm, newdata = valid_tbl, type = 'response')

claimrate_sim <- rpois(n_iter, sum(claim_rates))

ggplot() +
    geom_line(aes(x = claimrate_sim), stat = 'density') +
    geom_vline(aes(xintercept = valid_tbl$claim_nb %>% sum), colour = 'red') +
    xlab('Claim Count')
```

---

What about claim size?

---

Models little use

---

Assume average claim size

\


```{r calculate_mean_claim_size, echo=TRUE}
claim_tbl %>%
    filter(claim_amount <= 25000) %>%
    summarise(mean_amount = mean(claim_amount))
```

\

Use this for claim prediction

```{r create_claimsize_model, echo=FALSE}
claimsize_glm <- glm(claim_amount ~ 1
                    ,family = Gamma(link = 'log')
                    ,data   = claim_tbl %>% semi_join(train_tbl, by = 'policy_id'))
```


---

## Calculate Large Loss Charge

\

Estimate large-loss rate

```{r estimate_largeloss_rate, echo=TRUE}
largeclaim_count <- claim_tbl %>%
    filter(claim_amount >= 25000) %>%
    nrow

largeclaim_prop <- largeclaim_count / (policy_tbl$exposure %>% sum)

print(largeclaim_prop)
```

---

$\alpha = $ `r print(pl_scaling)`

\

Use to estimate mean of distribution

\

```{r generate_power_law, echo=FALSE}
sample_size <- 1000000

sample_pl <- rpldis(sample_size, xmin = 25000, alpha = pl_scaling)

expected_loss <- sample_pl %>% mean
```

$\mu = $ `r print(expected_loss)`

---

Large-loss charge:

\

```{r show_largeclaim_data, echo=TRUE}
expected_loss   %>% print
largeclaim_prop %>% print
(largeclaim_prop * expected_loss) %>% print
```



---


## Create Premium Quoter Function

\

Use higher-order functions

\

Takes policy table, produces price quotes


```{r create_premium_quoter_function, echo=FALSE}
create_pricing_function <- function(claimrate_model_glm
                                   ,claimsize_model_glm
                                   ,largeloss_charge
                                   ,quote_ratio) {

    price_function <- function(policy_tbl) {
        claim_rates <- predict(claimrate_model_glm
                              ,newdata = policy_tbl
                              ,type = 'response')

        claim_sizes <- predict(claimsize_model_glm
                              ,newdata = policy_tbl
                              ,type = 'response')

        expect_price <- claim_rates * claim_sizes
        risk_premium <- expect_price + largeloss_charge
        
        price_tbl <- data_frame(
            expect_price     = expect_price
           ,largeloss_charge = largeloss_charge
           ,risk_premium     = risk_premium
           ,quote_price      = risk_premium * (1 + quote_ratio)
        )
        
        return(price_tbl)
    }

    return(price_function)
}

premium_quoter <- create_pricing_function(
    claimrate_model_glm = model_02_glm
   ,claimsize_model_glm = claimgamma_glm
   ,largeloss_charge    = largeclaim_prop * expected_loss
   ,quote_ratio         = 0.35
)
```

\


```{r calculate_premium_price, echo=TRUE}
pricing_tbl <- premium_quoter(train_tbl) %>%
    mutate(policy_id = train_tbl$policy_id)

pricing_tbl %>% (knitr::kable)
```

# Assess the Pricing

\

Do the premia cover losses?

\

Do the premia give profit?

\

Can we test operational claims and large claims?


---

### MonteCarlo Simulation of Claims

\

Simulate claims using poisson model

\

For each claim, simulate claim size

\

Compare paid out losses to collected premia


---

### Test Training Data

\

Start with the training data

\

For consistency, this *SHOULD* match

\

Sanity-check for our approach

---

```{r sanity_check_training, echo=FALSE}
expect_amount <- predict(claimsize_glm, type = 'response')[1]

total_claims    <- claimrate_sim * expect_amount
collect_premium <- pricing_tbl %>%
    summarise(total_premium = sum(expect_price)) %>%
    .[['total_premium']]

ggplot() +
    geom_line(aes(x = total_claims), stat = 'density') +
    geom_vline(aes(xintercept = collect_premium), colour = 'red') +
    scale_x_continuous(labels = dollar) +
    xlab("Claims Paid")
```


# Future Steps

## Problems and Shortcomings

\

GLMs simplistic, may need overdispersed models

\

Need more validation / testing

\

Claims prediction needs work


## Future Improvements

\

Perform more thorough testing

\

Use Bayesian version - `stan_glm`

\

Improve linear models - GAMs



## Questions?

\

Email: mickcooney@gmail.com

\

GitHub: https://github.com/kaybenleroll/dublin_r_workshops


